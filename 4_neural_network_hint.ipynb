{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習（実践講義4）：Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題4.1 多層パーセプトロン学習プログラムの作成\n",
    "\n",
    "ニューラルネットワークによる学習を実現するプログラムを作成せよ． ここでは，ニューラルネットワークは，\n",
    "* 入力層\n",
    "* 中間層（隠れ層）\n",
    "* 出力層\n",
    "からなるものとする．\n",
    "\n",
    "このとき，特徴ベクトル（拡張特徴ベクトル）の要素数，パターン数，およびクラス数は任意の数を設定できるように作ること．\n",
    "\n",
    "\n",
    "**誤差逆伝播法の手順**\n",
    "\n",
    "1. 中間層と出力層の初期重みを決定する．\n",
    "1. 入力層から順番に，各ユニットの出力を計算していく．（中間層の出力をg1, 出力層の出力をg2とすると）\n",
    "  * 中間層のユニット数分ループしながらg1[j]の値を計算．\n",
    "  * 出力層のユニット数分ループしながらg2[k]の値を計算．\n",
    "1. 教科書P.46 式(3.68)やを参考に重みを修正．（入力層→中間層の重みをw1, 中間層→出力層の重みをw2とすると）\n",
    "  * ε[j]を計算． w2[j][k]の値を修正．\n",
    "  * 更新前のw2を用いてε[j]を計算． w1[i][j]の値を修正．\n",
    "1. 教科書P.47-48ページを参考に，収束の判定を行う．\n",
    "1. 手順２に戻る\n",
    "\n",
    "**実験用データ**\n",
    "\n",
    "完成したプログラムに，以下のデータを入力し，正しく学習することを確認せよ．\n",
    "ただし，\n",
    "$\\rho=1$\n",
    "とする．\n",
    "\n",
    "|パターン|値|クラス|\n",
    "| ---- | ---- | ---- |\n",
    "|パターン1|(1,1)|ω1|\n",
    "|パターン2|(2,1)|ω1|\n",
    "|パターン3|(1,3)|ω2|\n",
    "|パターン4|(2,4)|ω2|\n",
    "|パターン5|(4,3)|ω3|\n",
    "|パターン6|(4,2)|ω3|\n",
    "\n",
    "この数値データを値とクラスに分けてファイルに保存する．\n",
    "\n",
    "* data3.csv\n",
    "```\n",
    "1, 1\n",
    "2, 1\n",
    "1, 3\n",
    "2, 4\n",
    "4, 3\n",
    "4, 2\n",
    "```\n",
    "* label3.txt\n",
    "```\n",
    "1,0,0\n",
    "1,0,0\n",
    "0,1,0\n",
    "0,1,0\n",
    "0,0,1\n",
    "0,0,1\n",
    "```\n",
    "\n",
    "**ヒント**\n",
    "\n",
    "***拡張ベクトル化***\n",
    "\n",
    "```python\n",
    "x1 = np.hstack((x[p], [1]))\n",
    "```\n",
    "\n",
    "***重みの初期化***\n",
    "\n",
    "入力層2，中間層4，出力層3の場合\n",
    "```python\n",
    "w1 = np.random.rand(4, 2+1)  # 中間層の数 x 拡張ベクトルの長さ\n",
    "w2 = np.random.rand(3, 4+1)  # 出力層の数 x 中間の拡張ベクトルの長さ(中間層+1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***説明図***\n",
    "![プログラムの変数との対応](figure_bp.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 必要なモジュールの読み込み\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学習率\n",
    "rho = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "\n",
    "x = np.loadtxt(\"data3.csv\", delimiter=\",\")\n",
    "y = np.loadtxt(\"label3.txt\", delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  1.],\n",
       "        [ 2.,  1.],\n",
       "        [ 1.,  3.],\n",
       "        [ 2.,  4.],\n",
       "        [ 4.,  3.],\n",
       "        [ 4.,  2.]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1]]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w1 = np.random.randn(4, 3)\n",
    "w2 = np.random.randn(3, 5)\n",
    "\n",
    "tau = 0.01\n",
    "\n",
    "def sigmoid(s):\n",
    "    return 1/(1+np.exp(-s))\n",
    "       \n",
    "\n",
    "while True:\n",
    "    loss = 0\n",
    "    \n",
    "    for p in range(len(x)):\n",
    "        # xを拡張ベクトル化\n",
    "        x1 = np.hstack((x[p], [1]))\n",
    "        \n",
    "    \n",
    "     \n",
    "        # 1層目（x1とw1を使って計算）\n",
    "        layer1 = np.dot(x1, w1.T)\n",
    "        g1 = sigmoid(layer1)\n",
    "        \n",
    "     \n",
    "      \n",
    "        # 1層目の出力を拡張ベクトル化\n",
    "        g11 = np.hstack((g1, [1]))\n",
    "        \n",
    "        \n",
    "        # 2層目（g11とw2を使って計算）\n",
    "        layer2 = np.dot(g11, w2.T)\n",
    "        g2 = sigmoid(layer2)\n",
    "        \n",
    "        \n",
    "\n",
    "        # 誤差の合計を求めるため， x[p]に対する誤差を loss に加算 \n",
    "        loss += ((g2-y[p])**2)\n",
    "        #print(loss)\n",
    " \n",
    "        # eps1を計算するため，w2の更新前に，w2を一旦保存しておく（np.copyによりデータをコピー)\n",
    "        w2_old = np.copy(w2)\n",
    "\n",
    "        # g2とy[p]を使ってeps2[0], eps2[1], eps2[2]を計算\n",
    "        eps2 = (g2-y[p])*g2*(1 - g2)\n",
    "        \n",
    "        \n",
    "    \n",
    "        # w2を更新\n",
    "        for k in range(w2.shape[0]):\n",
    "            for j in range(w2.shape[1]):\n",
    "                w2[k, j] -= rho * np.dot(eps2[k],g11[j])\n",
    "                \n",
    "       \n",
    "        # eps2 と w2_old と g1を使ってeps1[0], eps1[1], eps1[2], eps1[3]を計算\n",
    "        eps1 = g1*(1 - g1)\n",
    "        for j in range(w1.shape[0]):\n",
    "            tmp = 0\n",
    "            for k in range(w2.shape[0]):\n",
    "                # ここで，eps2とw2_oldを利用\n",
    "                tmp += np.dot(eps2[k], w2_old[k,j])\n",
    "            eps1[j] *= tmp\n",
    "                \n",
    "        # w1を更新\n",
    "        for j in range(w1.shape[0]):\n",
    "            for i in range(w1.shape[1]):\n",
    "                w1[j, i] -= rho * np.dot(eps1[j], g11[i])\n",
    "        \n",
    "    # 誤差の平均 loss/データ数 が tau 以下ならループ終了\n",
    "    #print(loss /len(x))\n",
    "    #if loss / len(x) < tau:\n",
    "        #break\n",
    "        \n",
    "    flag = False\n",
    "    for b in range(len(loss)):\n",
    "        #print(loss[int(b)] / int(len(x)))\n",
    "        if loss[int(b)] / int(len(x)) < tau:\n",
    "            flag = True\n",
    "    if flag == True:\n",
    "        #print(w1, w2) \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51160276  0.15770685  0.23830848]\n",
      "0\n",
      "[ 0.43472456  0.04681183  0.56422654]\n",
      "2\n",
      "[ 0.08486657  0.88496244  0.05543941]\n",
      "1\n",
      "[ 0.07275264  0.90560828  0.05204636]\n",
      "1\n",
      "[ 0.31845623  0.05059283  0.64455955]\n",
      "2\n",
      "[ 0.31309137  0.02074666  0.79876293]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for p in range(len(x)):\n",
    "        # xを拡張ベクトル化\n",
    "        x1 = np.hstack((x[p], [1]))\n",
    "        \n",
    "    \n",
    "     \n",
    "        # 1層目（x1とw1を使って計算）\n",
    "        layer1 = np.dot(x1, w1.T)\n",
    "        g1 = sigmoid(layer1)\n",
    "        \n",
    "     \n",
    "      \n",
    "        # 1層目の出力を拡張ベクトル化\n",
    "        g11 = np.hstack((g1, [1]))\n",
    "        \n",
    "        \n",
    "        # 2層目（g11とw2を使って計算）\n",
    "        layer2 = np.dot(g11, w2.T)\n",
    "        g2 = sigmoid(layer2)\n",
    "\n",
    "        print(g2)\n",
    "        result = np.argmax(g2)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題4.2\n",
    "\n",
    "これまでの課題で用いた，アヤメのデータセット（iris_dataset）に対し，<br/>\n",
    "今回実装したニューラルネットワークを用いて認識し，認識率を計算せよ．\n",
    "\n",
    "以前実装した，パーセプトロンと比べて認識率がどうなるか調査し，考察せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 必要なモジュールの読み込み\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学習率\n",
    "rho = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "for i in range(len(iris.target)):\n",
    "    if iris.target[i] == 0:\n",
    "        target.append([1,0,0])\n",
    "    elif i == 1:\n",
    "        target.append([0,1,0])\n",
    "    else:\n",
    "        target.append([0,0,1])\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y=train_test_split(iris.data, target, test_size=0.8, random_state=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.9,  3. ,  5.1,  1.8],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 6.5,  3. ,  5.5,  1.8]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.8,  2.7,  5.1,  1.9]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1]]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p 0\n",
      "[ 0.91173739  0.94195682  0.93179951]\n",
      "loss: [ 0.83126507  0.88728265  0.00465131]\n",
      "p 1\n",
      "[ 0.86939579  0.92261773  0.93347229]\n",
      "loss: [ 1.58711412  1.73850613  0.00907724]\n",
      "p 2\n",
      "[ 0.78698261  0.88888471  0.93356795]\n",
      "loss: [ 1.63249052  2.52862216  0.88062636]\n",
      "p 3\n",
      "[ 0.81973113  0.82711848  0.91076934]\n",
      "loss: [ 2.30444965  3.21274714  0.88858847]\n",
      "p 4\n",
      "[ 0.68763305  0.70200337  0.9142967 ]\n",
      "loss: [ 2.77728887  3.70555588  0.89593353]\n",
      "p 5\n",
      "[ 0.47604319  0.49423275  0.91736839]\n",
      "loss: [ 3.00390599  3.94982189  0.90276151]\n",
      "p 6\n",
      "[ 0.31855622  0.32902923  0.9180669 ]\n",
      "loss: [ 3.46827162  4.05808213  1.74560834]\n",
      "p 7\n",
      "[ 0.51516883  0.23343866  0.88490176]\n",
      "loss: [ 3.73367054  4.11257573  1.75885594]\n",
      "p 8\n",
      "[ 0.32971274  0.19180155  0.89184239]\n",
      "loss: [ 3.84238104  4.14936357  1.77055401]\n",
      "p 9\n",
      "[ 0.24879181  0.17288348  0.89642984]\n",
      "loss: [ 4.40669479  4.17925226  2.57414047]\n",
      "p 10\n",
      "[ 0.42181196  0.1469238   0.84291437]\n",
      "loss: [ 4.58462012  4.20083887  2.59881636]\n",
      "p 11\n",
      "[ 0.28215066  0.13302163  0.8588437 ]\n",
      "loss: [ 4.66422911  4.21853362  2.61874146]\n",
      "p 12\n",
      "[ 0.21815249  0.12275499  0.87083152]\n",
      "loss: [ 4.71181962  4.23360241  2.63542596]\n",
      "p 13\n",
      "[ 0.18983845  0.12064664  0.87891774]\n",
      "loss: [ 5.36818135  4.24815802  3.40792235]\n",
      "p 14\n",
      "[ 0.31817981  0.10730444  0.80889704]\n",
      "loss: [ 5.46941975  4.25967226  3.44444269]\n",
      "p 15\n",
      "[ 0.23568947  0.10140568  0.83478662]\n",
      "loss: [ 5.52496927  4.26995537  3.47173815]\n",
      "p 16\n",
      "[ 0.20199779  0.10307621  0.85110929]\n",
      "loss: [ 6.1617768   4.28058008  4.19612516]\n",
      "p 17\n",
      "[ 0.33755096  0.09172121  0.75440572]\n",
      "loss: [ 6.27571745  4.28899286  4.25644171]\n",
      "p 18\n",
      "[ 0.24494729  0.08804742  0.80134976]\n",
      "loss: [ 6.33571662  4.29674521  4.29590363]\n",
      "p 19\n",
      "[ 0.19790745  0.08445368  0.82984406]\n",
      "loss: [ 6.37488398  4.30387763  4.32485667]\n",
      "p 20\n",
      "[ 0.17006558  0.08172959  0.8491645 ]\n",
      "loss: [ 6.40380628  4.31055736  4.34760802]\n",
      "p 21\n",
      "[ 0.15083302  0.0790872   0.86336231]\n",
      "loss: [ 6.42655689  4.31681214  4.36627788]\n",
      "p 22\n",
      "[ 0.14484098  0.08258703  0.87251799]\n",
      "loss: [ 7.15785383  4.32363276  5.12756553]\n",
      "p 23\n",
      "[ 0.22755375  0.07399834  0.79739196]\n",
      "loss: [ 7.20963454  4.32910851  5.16861555]\n",
      "p 24\n",
      "[ 0.20026009  0.07919787  0.82480238]\n",
      "loss: [ 7.84921847  4.33538082  5.84891452]\n",
      "p 25\n",
      "[ 0.32848241  0.06960633  0.70482066]\n",
      "loss: [ 7.95711916  4.34022586  5.93604536]\n",
      "p 26\n",
      "[ 0.2412974   0.06821969  0.77519824]\n",
      "loss: [ 8.0153436   4.34487978  5.98658119]\n",
      "p 27\n",
      "[ 0.19675305  0.06684376  0.81326201]\n",
      "loss: [ 8.05405536  4.34934787  6.02145227]\n",
      "p 28\n",
      "[ 0.16995947  0.0658177   0.837353  ]\n",
      "loss: [ 8.08294158  4.35367984  6.04790632]\n",
      "p 29\n",
      "[ 0.14900044  0.06328783  0.85501036]\n",
      "loss: [ 8.10514271  4.35768519  6.06892831]\n",
      "1 0.270171423742\n",
      "1 0.145256173058\n",
      "1 0.202297610372\n",
      "[[ 0.44964311  0.40529811  0.6371577   0.91520199  0.70842047]\n",
      " [ 0.52875326  0.34553823  0.60931586  0.40847412  0.43250134]\n",
      " [ 0.13814495 -0.01364635  0.72576101  0.2281832   0.27154139]\n",
      " [ 0.2978353   0.75955959  0.56971889  0.41560819  0.93505653]\n",
      " [ 0.6514423   0.29626068  0.51173103  0.88655756  0.72835505]] [[-0.67135293  0.15937013 -0.67305806 -0.05972215 -0.68602167  0.07242336]\n",
      " [-0.81805769 -0.00667099 -0.82470173 -0.18226735 -0.23496817 -0.65382293]\n",
      " [-0.10070409  0.25190402  0.13977358  0.71394045  0.45338893  0.4245194 ]]\n"
     ]
    }
   ],
   "source": [
    "w1 = np.random.rand(5, 4+1)  # 中間層の数 x 拡張ベクトルの長さ\n",
    "w2 = np.random.rand(3, 5+1)  # 出力層の数 x 中間の拡張ベクトルの長さ(中間層+1)\n",
    "tau = 0.01\n",
    "\n",
    "def sigmoid(s):\n",
    "    return 1/(1+np.exp(-s))\n",
    "       \n",
    "a = 0\n",
    "#while a < 2000:\n",
    "while True:\n",
    "    loss = 0\n",
    "    a += 1\n",
    "    \n",
    "    for p in range(len(train_X)):\n",
    "        print(\"p\", p)\n",
    "        # xを拡張ベクトル化\n",
    "        x1 = np.hstack((train_X[p], [1]))\n",
    "        \n",
    "        # 1層目（x1とw1を使って計算）\n",
    "        layer1 = np.dot(x1, w1.T)\n",
    "        g1 = sigmoid(layer1)\n",
    "        \n",
    "     \n",
    "      \n",
    "        # 1層目の出力を拡張ベクトル化\n",
    "        g11 = np.hstack((g1, [1]))\n",
    "        \n",
    "        \n",
    "        # 2層目（g11とw2を使って計算）\n",
    "        layer2 = np.dot(g11, w2.T)\n",
    "        g2 = sigmoid(layer2)\n",
    "        print(g2)\n",
    "        \n",
    "\n",
    "        # 誤差の合計を求めるため， x[p]に対する誤差を loss に加算 \n",
    "        loss += (g2-train_y[p])**2\n",
    "        print(\"loss: \" + str(loss))\n",
    "       \n",
    " \n",
    "        # eps1を計算するため，w2の更新前に，w2を一旦保存しておく（np.copyによりデータをコピー)\n",
    "        w2_old = np.copy(w2)\n",
    "\n",
    "        # g2とy[p]を使ってeps2[0], eps2[1], eps2[2]を計算\n",
    "        eps2 = (g2-train_y[p])*g2*(1 - g2)\n",
    "        \n",
    "        \n",
    "    \n",
    "        # w2を更新\n",
    "        for k in range(w2.shape[0]):\n",
    "            for j in range(w2.shape[1]):\n",
    "                w2[k, j] -= rho * np.dot(eps2[k],g11[j])\n",
    "                \n",
    "       \n",
    "        # eps2 と w2_old と g1を使ってeps1[0], eps1[1], eps1[2], eps1[3]を計算\n",
    "        eps1 = g1*(1 - g1)\n",
    "        for j in range(w1.shape[0]):\n",
    "            tmp = 0\n",
    "            for k in range(w2.shape[0]):\n",
    "                # ここで，eps2とw2_oldを利用\n",
    "                tmp += np.dot(eps2[k], w2_old[k,j])\n",
    "            eps1[j] *= tmp\n",
    "                \n",
    "        # w1を更新\n",
    "        for j in range(w1.shape[0]):\n",
    "            for i in range(w1.shape[1]):\n",
    "                w1[j, i] -= rho * np.dot(eps1[j], g11[i])\n",
    "        \n",
    "    # 誤差の平均 loss/データ数 が tau 以下ならループ終了\n",
    "    #print(loss /len(x))\n",
    "    #if loss / len(x) < tau:\n",
    "        #break\n",
    "    \n",
    "    #flag = False    \n",
    "    for b in range(len(loss)):\n",
    "        print(a,loss[int(b)] / int(len(train_X)))\n",
    "        if loss[int(b)] / int(len(train_X)) < tau:\n",
    "            flag = False\n",
    "    if flag == False:\n",
    "        break\n",
    "        \n",
    "print(w1,w2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44964311  0.40529811  0.6371577   0.91520199  0.70842047]\n",
      " [ 0.52875326  0.34553823  0.60931586  0.40847412  0.43250134]\n",
      " [ 0.13814495 -0.01364635  0.72576101  0.2281832   0.27154139]\n",
      " [ 0.2978353   0.75955959  0.56971889  0.41560819  0.93505653]\n",
      " [ 0.6514423   0.29626068  0.51173103  0.88655756  0.72835505]] [[-0.67135293  0.15937013 -0.67305806 -0.05972215 -0.68602167  0.07242336]\n",
      " [-0.81805769 -0.00667099 -0.82470173 -0.18226735 -0.23496817 -0.65382293]\n",
      " [-0.10070409  0.25190402  0.13977358  0.71394045  0.45338893  0.4245194 ]]\n",
      "[ 0.13616657  0.06255434  0.86760754]\n",
      "[ 0.14501514  0.06800131  0.86545103]\n",
      "[ 0.14646203  0.06890842  0.86511735]\n",
      "[ 0.13545482  0.06211837  0.86779599]\n",
      "[ 0.13517059  0.06194452  0.86786516]\n",
      "[ 0.13504728  0.0618688   0.86789869]\n",
      "[ 0.13500044  0.06184019  0.86790866]\n",
      "[ 0.13623838  0.06259855  0.86757409]\n",
      "[ 0.13571461  0.06227708  0.86772203]\n",
      "[ 0.13610422  0.06251725  0.86759962]\n",
      "[ 0.14518283  0.06812353  0.86557873]\n",
      "[ 0.13592603  0.06240692  0.8676648 ]\n",
      "[ 0.14670552  0.06907157  0.86510964]\n",
      "[ 0.14495402  0.06797493  0.865579  ]\n",
      "[ 0.13583512  0.06235105  0.86770245]\n",
      "[ 0.13512484  0.06191638  0.86787817]\n",
      "[ 0.13511938  0.06191291  0.86788203]\n",
      "[ 0.13522258  0.06197613  0.86785657]\n",
      "[ 0.13564176  0.06223272  0.86774741]\n",
      "[ 0.14926299  0.07064503  0.86428958]\n",
      "[ 0.1363597   0.06267341  0.86753451]\n",
      "[ 0.14254874  0.06646501  0.86608241]\n",
      "[ 0.14533097  0.06821085  0.86534997]\n",
      "[ 0.13502376  0.06185423  0.86790587]\n",
      "[ 0.14589736  0.06855014  0.8652321 ]\n",
      "[ 0.13499653  0.06183762  0.86791185]\n",
      "[ 0.1351753   0.06194721  0.86786687]\n",
      "[ 0.13572969  0.06228783  0.86770061]\n",
      "[ 0.13621683  0.06258558  0.86758557]\n",
      "[ 0.13763341  0.06345652  0.86720191]\n",
      "[ 0.14312329  0.0668425   0.86600921]\n",
      "[ 0.13561873  0.06222011  0.86773643]\n",
      "[ 0.14459043  0.06774261  0.8656376 ]\n",
      "[ 0.13560106  0.06220737  0.86776593]\n",
      "[ 0.13669853  0.06288049  0.86746522]\n",
      "[ 0.13724146  0.06321379  0.86727877]\n",
      "[ 0.13564924  0.06223705  0.86775226]\n",
      "[ 0.13508595  0.0618925   0.86788896]\n",
      "[ 0.14525643  0.06816032  0.86546496]\n",
      "[ 0.13543034  0.06210379  0.8677935 ]\n",
      "[ 0.13554112  0.06217122  0.86777393]\n",
      "[ 0.14267082  0.06655988  0.86608382]\n",
      "[ 0.14509354  0.06805933  0.86555566]\n",
      "[ 0.1490551   0.07053661  0.8646206 ]\n",
      "[ 0.14699101  0.06922846  0.86493885]\n",
      "[ 0.13607886  0.06250081  0.86762496]\n",
      "[ 0.13514152  0.06192654  0.86787576]\n",
      "[ 0.13591124  0.06239741  0.86767679]\n",
      "[ 0.13538736  0.06207669  0.86781697]\n",
      "[ 0.13516406  0.06194054  0.86786703]\n",
      "[ 0.14484935  0.06791137  0.865616  ]\n",
      "[ 0.14420464  0.06750622  0.86580791]\n",
      "[ 0.1352141   0.06197084  0.8678564 ]\n",
      "[ 0.13529575  0.06202081  0.86783915]\n",
      "[ 0.13509538  0.06189824  0.86788697]\n",
      "[ 0.13539299  0.06208083  0.86780822]\n",
      "[ 0.13605413  0.06248459  0.86763255]\n",
      "[ 0.14567481  0.06842682  0.86541986]\n",
      "[ 0.1444504   0.06765745  0.86568097]\n",
      "[ 0.1438204   0.06726204  0.86588773]\n",
      "[ 0.13598637  0.06244373  0.86765515]\n",
      "[ 0.14400297  0.06737861  0.86568454]\n",
      "[ 0.14542585  0.06827729  0.86562465]\n",
      "[ 0.14326871  0.06693032  0.86611796]\n",
      "[ 0.13536787  0.06206528  0.86781116]\n",
      "[ 0.13509325  0.06189683  0.86788743]\n",
      "[ 0.14544077  0.06827594  0.86533173]\n",
      "[ 0.14521488  0.06812324  0.86536484]\n",
      "[ 0.13537585  0.06207088  0.86780565]\n",
      "[ 0.13505188  0.0618715   0.86789898]\n",
      "[ 0.13554824  0.06217529  0.86777018]\n",
      "[ 0.1351401   0.06192594  0.86787011]\n",
      "[ 0.13600303  0.0624534   0.86765624]\n",
      "[ 0.13577428  0.06231364  0.86771613]\n",
      "[ 0.13568691  0.06226014  0.86773457]\n",
      "[ 0.13600067  0.06245266  0.86765779]\n",
      "[ 0.13593699  0.06241268  0.86767256]\n",
      "[ 0.1353473   0.06205295  0.86781657]\n",
      "[ 0.13540846  0.06208996  0.86780769]\n",
      "[ 0.1354201   0.06209758  0.86779932]\n",
      "[ 0.1352365   0.06198469  0.86784234]\n",
      "[ 0.14252092  0.06646339  0.8662159 ]\n",
      "[ 0.13500752  0.06184448  0.86790757]\n",
      "[ 0.13570032  0.06226965  0.86771802]\n",
      "[ 0.13515661  0.06193567  0.86787295]\n",
      "[ 0.14440171  0.06761744  0.86559783]\n",
      "[ 0.13556385  0.06218479  0.86776992]\n",
      "[ 0.1350694   0.0618824   0.86789167]\n",
      "[ 0.14238081  0.06637728  0.86625151]\n",
      "[ 0.14484327  0.06791375  0.86571331]\n",
      "[ 0.14353385  0.06709206  0.86588911]\n",
      "[ 0.14587766  0.06853902  0.865204  ]\n",
      "[ 0.14361533  0.06714904  0.8659095 ]\n",
      "[ 0.13509599  0.06189864  0.86788615]\n",
      "[ 0.13534676  0.06205281  0.86781687]\n",
      "[ 0.13519578  0.06195977  0.86785863]\n",
      "[ 0.14501514  0.06800131  0.86545103]\n",
      "[ 0.14451527  0.06769285  0.86578028]\n",
      "[ 0.13524749  0.06199135  0.86785166]\n",
      "[ 0.13525401  0.06199566  0.86784315]\n",
      "[ 0.14560141  0.06837059  0.86536031]\n",
      "[ 0.13550091  0.06214605  0.86779034]\n",
      "[ 0.13647764  0.06274495  0.86753824]\n",
      "[ 0.13526719  0.06200349  0.86784399]\n",
      "[ 0.14416641  0.06748236  0.86581534]\n",
      "[ 0.13563896  0.06223061  0.86775715]\n",
      "[ 0.1372072   0.06319377  0.86728197]\n",
      "[ 0.13529611  0.06202171  0.86783314]\n",
      "[ 0.13513506  0.06192244  0.86787626]\n",
      "[ 0.14628659  0.06878857  0.86500585]\n",
      "[ 0.14184972  0.06604291  0.86633225]\n",
      "[ 0.13512343  0.06191538  0.86788071]\n",
      "[ 0.14427028  0.06753915  0.86561862]\n",
      "[ 0.13582533  0.06234499  0.8676835 ]\n",
      "[ 0.14430779  0.06756985  0.8657422 ]\n",
      "[ 0.14403581  0.06740254  0.86585282]\n",
      "[ 0.13497968  0.06182754  0.86791335]\n",
      "[ 0.13650841  0.06276423  0.86749397]\n",
      "[ 0.14290474  0.06669865  0.86605924]\n",
      "[ 0.1353473   0.06205295  0.86781657]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(w1, w2)\n",
    "result = []\n",
    "for p in range(len(test_X)):\n",
    "        # xを拡張ベクトル化\n",
    "        x1 = np.hstack((test_X[p], [1]))\n",
    "        \n",
    "        # 1層目（x1とw1を使って計算）\n",
    "        layer1 = np.dot(x1, w1.T)\n",
    "        g1 = sigmoid(layer1)\n",
    "        \n",
    "     \n",
    "      \n",
    "        # 1層目の出力を拡張ベクトル化\n",
    "        g11 = np.hstack((g1, [1]))\n",
    "        \n",
    "        \n",
    "        # 2層目（g11とw2を使って計算）\n",
    "        layer2 = np.dot(g11, w2.T)\n",
    "        g2 = sigmoid(layer2)\n",
    "        \n",
    "        print(g2)\n",
    "        result.append(np.argmax(g2))\n",
    "print(result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-28dcd76457d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcorrectness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mcorrectness\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrectness\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "correctness = 0\n",
    "for n in range(len(test_y)):\n",
    "    if result[n] == test_y[n]:\n",
    "        correctness += 1\n",
    "print(correctness / len(result))\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
